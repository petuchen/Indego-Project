{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(jupyter.plot_mimetypes = c(\"text/plain\", \"image/png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2); library(caret); library(plyr); library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data <- read.csv(\"indego_df_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data$start_hour <- factor(data$start_hour)\n",
    "data$start_station <- factor(data$start_station)\n",
    "levels(data$duration_type)[levels(data$duration_type)==\"very short\"] <- \"very_short\"\n",
    "data$duration_type <- factor(data$duration_type, levels=c(\"very_short\", \"short\", \"medium\", \"long\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_small <- sample_n(data, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5000 obs. of  22 variables:\n",
      " $ X                  : int  66587 407901 539462 1874021 1028033 1013834 109059 653232 1204661 1634862 ...\n",
      " $ trip_id            : int  38711074 203530174 92073603 4054767 183055625 180646194 39220841 60823819 4691997 4496302 ...\n",
      " $ duration           : num  16 11 18 25 70 13 88 9 13 10 ...\n",
      " $ start_time         : Factor w/ 833217 levels \"2015-04-23 07:44:00\",..: 339604 731641 489692 16822 692355 687773 356053 414470 271393 185706 ...\n",
      " $ end_time           : Factor w/ 819051 levels \"2015-04-23 07:45:00\",..: 331697 718572 479571 16204 679636 675043 347897 405401 264787 180869 ...\n",
      " $ start_station      : Factor w/ 127 levels \"3004\",\"3005\",..: 18 2 31 19 83 57 53 17 83 7 ...\n",
      " $ start_lat          : num  40 39.9 39.9 40 39.9 ...\n",
      " $ start_lon          : num  -75.2 -75.1 -75.2 -75.2 -75.2 ...\n",
      " $ end_station        : int  3026 3100 3020 3028 3046 3129 3058 3032 3010 3066 ...\n",
      " $ end_lat            : num  39.9 39.9 39.9 39.9 40 ...\n",
      " $ end_lon            : num  -75.1 -75.2 -75.2 -75.1 -75.1 ...\n",
      " $ bike_id            : Factor w/ 1926 levels \"03556A\",\"102\",..: 357 1370 20 1425 1469 174 1877 1787 1732 1065 ...\n",
      " $ plan_duration      : int  0 365 30 30 0 30 365 30 30 30 ...\n",
      " $ trip_route_category: Factor w/ 2 levels \"One Way\",\"Round Trip\": 1 1 1 1 1 1 2 1 1 1 ...\n",
      " $ passholder_type    : Factor w/ 6 levels \"Indego30\",\"Indego365\",..: 6 3 1 1 6 1 3 1 1 1 ...\n",
      " $ duration_type      : Factor w/ 4 levels \"very_short\",\"short\",..: 2 1 2 2 4 1 4 1 1 1 ...\n",
      " $ distance           : num  2.43 2.26 2.92 3.27 1.49 ...\n",
      " $ start_weekday      : Factor w/ 7 levels \"Friday\",\"Monday\",..: 7 1 1 1 4 7 3 1 3 1 ...\n",
      " $ start_hour         : Factor w/ 24 levels \"0\",\"1\",\"2\",\"3\",..: 16 12 10 20 17 8 20 20 13 15 ...\n",
      " $ start_date         : Factor w/ 1072 levels \"2015-04-23\",\"2015-04-24\",..: 460 917 644 23 877 873 477 539 386 233 ...\n",
      " $ isBday             : num  1 1 1 1 0 1 0 1 0 1 ...\n",
      " $ start_month        : int  7 10 1 5 9 9 8 10 5 12 ...\n"
     ]
    }
   ],
   "source": [
    "str(data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inTrain <- createDataPartition(y=data_small$duration_type, p=0.7, list=FALSE)\n",
    "training <- data_small[inTrain,]\n",
    "testing <- data_small[-inTrain,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# formula <- duration_type ~ start_station + passholder_type + start_weekday + start_hour\n",
    "formula <- duration_type ~ isBday + passholder_type + start_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model with default paramters\n",
    "control <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n",
    "metric <- \"Accuracy\"\n",
    "mtry <- sqrt(ncol(training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "1402 samples\n",
      "   3 predictor\n",
      "   4 classes: 'very_short', 'short', 'medium', 'long' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Bootstrapped (25 reps) \n",
      "Summary of sample sizes: 1402, 1402, 1402, 1402, 1402, 1402, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  Accuracy   Kappa      \n",
      "   2    0.6599207  0.004230985\n",
      "  15    0.6409927  0.129502829\n",
      "  29    0.6389667  0.127981506\n",
      "\n",
      "Accuracy was used to select the optimal model using  the largest value.\n",
      "The final value used for the model was mtry = 2.\n"
     ]
    }
   ],
   "source": [
    "model_rf <- train(formula, data=training, method=\"rf\", prox=TRUE)\n",
    "print(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘ranger’ was built under R version 3.4.4”\n",
      "Attaching package: ‘ranger’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    importance\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "1402 samples\n",
      "   3 predictor\n",
      "   4 classes: 'very_short', 'short', 'medium', 'long' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
      "Summary of sample sizes: 1261, 1262, 1262, 1263, 1261, 1262, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  splitrule   Accuracy   Kappa       \n",
      "   2    gini        0.6552688  0.0002113749\n",
      "   2    extratrees  0.6557450  0.0009880549\n",
      "  15    gini        0.6424468  0.1160161205\n",
      "  15    extratrees  0.6393583  0.1115679930\n",
      "  29    gini        0.6391152  0.1126795598\n",
      "  29    extratrees  0.6362816  0.1089425659\n",
      "\n",
      "Accuracy was used to select the optimal model using  the largest value.\n",
      "The final values used for the model were mtry = 2 and splitrule = extratrees.\n"
     ]
    }
   ],
   "source": [
    "# ranger is another RF package with speed improvement\n",
    "model_ranger <- train(formula, data=training, method=\"ranger\", metric=metric, trControl=control)\n",
    "print(model_ranger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. XGboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv.ctrl <- trainControl(method = \"repeatedcv\", repeats = 5, number = 3, \n",
    "                        classProbs = TRUE,\n",
    "                        allowParallel=T)\n",
    "\n",
    "xgb.grid <- expand.grid(nrounds = 100,\n",
    "                        eta = c(0.4,0.7),\n",
    "                        max_depth = c(2,3,4),\n",
    "                        gamma = 0,\n",
    "                        colsample_bytree = .7,\n",
    "                        min_child_weight = 1,\n",
    "                        subsample = c(.8, 1)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eXtreme Gradient Boosting \n",
      "\n",
      "3502 samples\n",
      "   3 predictor\n",
      "   4 classes: 'very_short', 'short', 'medium', 'long' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (3 fold, repeated 5 times) \n",
      "Summary of sample sizes: 2334, 2335, 2335, 2336, 2334, 2334, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  eta  max_depth  subsample  Accuracy   Kappa    \n",
      "  0.4  2          0.8        0.6420907  0.1452312\n",
      "  0.4  2          1.0        0.6430603  0.1499159\n",
      "  0.4  3          0.8        0.6434029  0.1572003\n",
      "  0.4  3          1.0        0.6434599  0.1538785\n",
      "  0.4  4          0.8        0.6426612  0.1506443\n",
      "  0.4  4          1.0        0.6431175  0.1533987\n",
      "  0.7  2          0.8        0.6420329  0.1461228\n",
      "  0.7  2          1.0        0.6419753  0.1472666\n",
      "  0.7  3          0.8        0.6433464  0.1566673\n",
      "  0.7  3          1.0        0.6435749  0.1506564\n",
      "  0.7  4          0.8        0.6438604  0.1616273\n",
      "  0.7  4          1.0        0.6427749  0.1554699\n",
      "\n",
      "Tuning parameter 'nrounds' was held constant at a value of 100\n",
      "Tuning\n",
      " parameter 'colsample_bytree' was held constant at a value of 0.7\n",
      "\n",
      "Tuning parameter 'min_child_weight' was held constant at a value of 1\n",
      "Kappa was used to select the optimal model using  the largest value.\n",
      "The final values used for the model were nrounds = 100, max_depth = 4, eta\n",
      " = 0.7, gamma = 0, colsample_bytree = 0.7, min_child_weight = 1 and subsample\n",
      " = 0.8.\n"
     ]
    }
   ],
   "source": [
    "model_xgb <-train(formula,\n",
    "                 data=training,\n",
    "                 method=\"xgbTree\",\n",
    "                 trControl=cv.ctrl,\n",
    "                 tuneGrid=xgb.grid,\n",
    "                 verbose=T,\n",
    "                 metric=\"Kappa\"\n",
    "                 )\n",
    "\n",
    "print(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
